{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c8bebffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mpmath import nsum, nprod, fac\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "048dae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parameters(p_denial, Q, A, D):\n",
    "    print('\\nDenial probability: ', p_denial)\n",
    "    print('Relative volume: ', Q)\n",
    "    print('Absolute volume:', A)\n",
    "    print('Income:', D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8648dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequestSubmit:\n",
    "    def __init__(self, timepoint, type_of_request):\n",
    "        self.timepoint = timepoint\n",
    "        self.type_of_request = type_of_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "55de7cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequestProcess:\n",
    "    def __init__(self, start_timepoint, timepoint, terminal_no, type_of_request):\n",
    "        self.start_timepoint = start_timepoint\n",
    "        self.timepoint = timepoint\n",
    "        self.terminal_no = terminal_no\n",
    "        self.type_of_request = type_of_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "579b32bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacteristicsShower():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def empirical(self):\n",
    "        print('\\nEmpirical characteristics:')\n",
    "        \n",
    "        print('Processed requests: ', self.model.requests_processed)\n",
    "        print('Denied requests: ', self.model.requests_denied)\n",
    "\n",
    "        probs, ps = self.calculate_probs_emp()\n",
    "\n",
    "        p_denial, Q, A, D = self.calculate_Q_A_D(ps, 'empirical')\n",
    "        \n",
    "        print_parameters(p_denial, Q, A, D)\n",
    "        \n",
    "        return probs\n",
    "        \n",
    "    \"\"\"def theoretical(self):\n",
    "        print('\\nTheoretical characteristics:')\n",
    "        \n",
    "        ro = self.model.lambda_ / self.model.mu\n",
    "        p0 = 1 / (nsum(lambda k: ro ** k / fac(k), [0, self.model.number_of_channels]) + (ro ** self.model.number_of_channels / fac(self.model.number_of_channels)) \\\n",
    "                  * nsum(lambda i: ro ** i / nprod(lambda l: (self.model.number_of_channels + l * self.model.nu / self.model.mu), [1, i]), [1, self.model.m])) \n",
    "        print(f'Probability is equal to {p0} when 0 terminals are busy')\n",
    "        \n",
    "        avg_processing, ps, probs = self.calculate_probs_theor(p0, ro)\n",
    "        \n",
    "        p_denial, Q, A, avg_processing_time, avg_waiting_time, avg_total_time = self.calculate_Q_A_and_total_time(ps, 'theoretical')\n",
    "        \n",
    "        print_parameters(p_denial, Q, A, D)\n",
    " \n",
    "        return probs\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    def calculate_Q_A_D(self, ps, char_type):\n",
    "        p_denial = ps\n",
    "        Q = 1 - p_denial\n",
    "        A = self.model.intensity_flow * Q\n",
    "        D = A * self.model.income_from_one_request\n",
    "\n",
    "        return p_denial, Q, A, D\n",
    "    \n",
    "    def calculate_probs_emp(self):\n",
    "        probs = []\n",
    "        for k in range(self.model.number_of_channels + 1):\n",
    "            pk = self.model.final_state_durations[k] / self.model.timeline[-1].timepoint\n",
    "            probs.append(pk)\n",
    "            print(f'Probability is equal to {pk} when {k} terminals are busy')\n",
    "\n",
    "        return probs, pk\n",
    "    \n",
    "    \"\"\"def calculate_probs_theor(self, p0, ro):\n",
    "        avg_processing = 0\n",
    "        probs = [p0]\n",
    "        for k in range(1, self.model.number_of_channels + 1):\n",
    "            pk = ro ** k * p0 / fac(k)\n",
    "            probs.append(pk)\n",
    "            avg_processing += k * pk\n",
    "            print(f'Probability is equal to {pk} when {k} terminals are busy')\n",
    "\n",
    "        return avg_processing, ps, probs\n",
    "        \"\"\"\n",
    "\n",
    "    def plot_graphs(self):\n",
    "        empirical_probs = self.empirical()\n",
    "        \"\"\"theoretical_probs = self.theoretical()\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(empirical_probs, label='empirical')\n",
    "        ax.plot(theoretical_probs, label='theoretical')\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots(1, 2)\n",
    "        ax[0].title.set_text('Empirical probabilities')\n",
    "        ax[0].hist(list(np.arange(0, len(empirical_probs), 1)), weights=empirical_probs)\n",
    "        ax[1].title.set_text('Theoretical probabilities')\n",
    "        ax[1].hist(list(np.arange(0, len(theoretical_probs), 1)), weights=theoretical_probs)\n",
    "        \n",
    "        plt.show()\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "665c175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SystemOfMassServiceModel:\n",
    "    def __init__(self, number_of_channels, intensity_flow, avg_processing_time, intensity_flow_service, income_from_one_request, \n",
    "                 maintenance_of_one_channel, max_requests_num):\n",
    "        self.number_of_channels = number_of_channels\n",
    "        self.intensity_flow = intensity_flow\n",
    "        self.avg_processing_time = avg_processing_time\n",
    "        self.intensity_flow_service = intensity_flow_service\n",
    "        self.income_from_one_request = income_from_one_request\n",
    "        self.maintenance_of_one_channel = maintenance_of_one_channel\n",
    "        self.max_requests_num = max_requests_num\n",
    "\n",
    "        self.total_income = 0\n",
    "        \n",
    "        self.terminal_availabilities = [True for _ in range(number_of_channels)]\n",
    "        self.busy_terminals = 0\n",
    "        \n",
    "        self.timeline = []\n",
    "        self.final_state_durations = [0] * (number_of_channels + 0 + 1)\n",
    "        self.state_durations = []\n",
    "        self.last_state = 0\n",
    "        self.last_state_change_timepoint = 0\n",
    "\n",
    "        self.requests_processed = 0\n",
    "        self.requests_denied = 0\n",
    "\n",
    "    def modeling(self):\n",
    "        requests, services = self.get_generated_values()\n",
    "\n",
    "        self.timeline.append(RequestSubmit(next(requests), 'submitted'))\n",
    "\n",
    "        self.add_submits_to_timeline(requests)\n",
    "            \n",
    "        for event in self.timeline:\n",
    "            if event.type_of_request == 'submitted':\n",
    "                terminal_available, terminal_no = self.find_available_terminal()\n",
    "\n",
    "                if terminal_available:\n",
    "                    self.process_request(event, services, terminal_no)\n",
    "                else:\n",
    "                    self.requests_denied += 1\n",
    "            else:\n",
    "                self.make_terminal_available(event)\n",
    "                self.record_state(event.timepoint)\n",
    "                \n",
    "    def add_submits_to_timeline(self, requests):\n",
    "        for i in range(self.max_requests_num - 1):\n",
    "            timepoint = self.timeline[len(self.timeline) - 1].timepoint + next(requests)\n",
    "            self.timeline.append(RequestSubmit(timepoint, 'submitted'))\n",
    "                \n",
    "    def make_terminal_available(self, event):\n",
    "        self.requests_processed += 1\n",
    "        self.total_income += self.income_from_one_request\n",
    "        self.busy_terminals -= 1\n",
    "        self.terminal_availabilities[event.terminal_no] = True\n",
    " \n",
    "    def process_request(self, event, services, terminal_no):\n",
    "        self.insert(RequestProcess(event.timepoint, event.timepoint + next(services), terminal_no, 'processed'))\n",
    "        self.record_state(event.timepoint)\n",
    "\n",
    "    def insert(self, event):\n",
    "        for i in range(1, len(self.timeline)):\n",
    "            if event.timepoint > self.timeline[i - 1].timepoint and event.timepoint < self.timeline[i].timepoint:\n",
    "                self.timeline.insert(i, event)\n",
    "                break\n",
    "        else:\n",
    "            self.timeline.append(event)\n",
    "\n",
    "    def find_available_terminal(self):\n",
    "        for i in range(len(self.terminal_availabilities)):\n",
    "            if self.terminal_availabilities[i]:\n",
    "                self.busy_terminals += 1\n",
    "                self.terminal_availabilities[i] = False\n",
    "                return True, i\n",
    "        \n",
    "        return False, -1\n",
    "                \n",
    "    def record_state(self, timepoint):\n",
    "        delta = timepoint - self.last_state_change_timepoint\n",
    "        self.final_state_durations[self.last_state] += delta\n",
    "\n",
    "        self.last_state_change_timepoint = timepoint\n",
    "        self.last_state = self.busy_terminals\n",
    "\n",
    "        self.state_durations.append((timepoint, self.final_state_durations.copy()))\n",
    "        \n",
    "    def generate_values(self, value):\n",
    "        while True:\n",
    "            yield np.random.exponential(1 / value)\n",
    "            \n",
    "    def get_generated_values(self):\n",
    "        requests = self.generate_values(self.intensity_flow)\n",
    "        services = self.generate_values(self.intensity_flow_service)\n",
    "        \n",
    "        return requests, services\n",
    "        \n",
    "    \"\"\"\n",
    "    Numpy suggests using default_rng(), but it doesn't return generator\n",
    "    and it only makes things harder for us\n",
    "    \n",
    "    def get_generated_values(self):\n",
    "        rng = np.random.default_rng() \n",
    "        requests = rng.exponential(1 / self.lambda_, self.max_requests)\n",
    "        services = rng.exponential(1 / self.mu, self.max_requests)\n",
    "        waitings = rng.exponential(1 / self.nu, self.max_requests)\n",
    "        return requests, services, waitings\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "78ed32eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELING WITH THE NEXT PARAMETERS: number_of_channels = 2, intensity_flow = 4\n",
      "\n",
      "Empirical characteristics:\n",
      "Processed requests:  437\n",
      "Denied requests:  563\n",
      "Probability is equal to 0.11650487959665157 when 0 terminals are busy\n",
      "Probability is equal to 0.32148032099121604 when 1 terminals are busy\n",
      "Probability is equal to 0.5620147994121324 when 2 terminals are busy\n",
      "\n",
      "Denial probability:  0.5620147994121324\n",
      "Relative volume:  0.4379852005878676\n",
      "Absolute volume: 1.7519408023514704\n",
      "Income: 7.007763209405882\n"
     ]
    }
   ],
   "source": [
    "number_of_channels = 2\n",
    "intensity_flow = 4\n",
    "avg_processing_time = 0.8\n",
    "intensity_flow_service = 1 / avg_processing_time\n",
    "income_from_one_request = 4\n",
    "maintenance_of_one_channel = 2\n",
    "max_requests_num = 1000\n",
    "\n",
    "model = SystemOfMassServiceModel(number_of_channels, intensity_flow, avg_processing_time, intensity_flow_service, income_from_one_request, maintenance_of_one_channel, max_requests_num)\n",
    "model.modeling()\n",
    "print(f'MODELING WITH THE NEXT PARAMETERS: number_of_channels = {model.number_of_channels}, intensity_flow = {model.intensity_flow}')\n",
    "model_characteristics = CharacteristicsShower(model)\n",
    "model_characteristics.plot_graphs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
